{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apspk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apspk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "619/619 - 56s - 90ms/step - accuracy: 0.7080 - loss: 0.6808 - val_accuracy: 0.8104 - val_loss: 0.5103\n",
      "Epoch 2/10\n",
      "619/619 - 64s - 103ms/step - accuracy: 0.8327 - loss: 0.4450 - val_accuracy: 0.8154 - val_loss: 0.4950\n",
      "Epoch 3/10\n",
      "619/619 - 61s - 99ms/step - accuracy: 0.8606 - loss: 0.3816 - val_accuracy: 0.8204 - val_loss: 0.5125\n",
      "Epoch 4/10\n",
      "619/619 - 58s - 93ms/step - accuracy: 0.8713 - loss: 0.3444 - val_accuracy: 0.8122 - val_loss: 0.5244\n",
      "Epoch 5/10\n",
      "619/619 - 50s - 80ms/step - accuracy: 0.8860 - loss: 0.3168 - val_accuracy: 0.8131 - val_loss: 0.5431\n",
      "Epoch 6/10\n",
      "619/619 - 52s - 85ms/step - accuracy: 0.8949 - loss: 0.2934 - val_accuracy: 0.8049 - val_loss: 0.5830\n",
      "Epoch 7/10\n",
      "619/619 - 53s - 85ms/step - accuracy: 0.9015 - loss: 0.2732 - val_accuracy: 0.8040 - val_loss: 0.6123\n",
      "Epoch 8/10\n",
      "619/619 - 53s - 86ms/step - accuracy: 0.9088 - loss: 0.2522 - val_accuracy: 0.8045 - val_loss: 0.6455\n",
      "Epoch 9/10\n",
      "619/619 - 58s - 94ms/step - accuracy: 0.9126 - loss: 0.2357 - val_accuracy: 0.8049 - val_loss: 0.7000\n",
      "Epoch 10/10\n",
      "619/619 - 53s - 86ms/step - accuracy: 0.9183 - loss: 0.2199 - val_accuracy: 0.8031 - val_loss: 0.7302\n",
      "172/172 - 6s - 37ms/step\n",
      "LSTM Accuracy: 0.8062579588866654\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1562\n",
      "           1       0.80      0.82      0.81      2230\n",
      "           2       0.85      0.82      0.83      1705\n",
      "\n",
      "    accuracy                           0.81      5497\n",
      "   macro avg       0.81      0.80      0.81      5497\n",
      "weighted avg       0.81      0.81      0.81      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Step 1: Data Collection\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"sentiment_analysis.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Step 2: Text Preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"\\W\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Apply the preprocess_text function\n",
    "df[\"selected_text\"] = df[\"selected_text\"].fillna(\"\")\n",
    "df[\"clean_text\"] = df[\"selected_text\"].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Feature Extraction\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df[\"clean_text\"])\n",
    "X = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "y = pd.get_dummies(df[\"sentiment\"]).values\n",
    "\n",
    "# Step 4: Model Selection and Training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=2)\n",
    "\n",
    "# Step 6: Model Evaluation\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=2)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)\n",
    "\n",
    "print(\"LSTM Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"LSTM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"sentiment_analysis_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
